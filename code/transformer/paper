1.Vision Transformer (ViT)——An image is worth 16x16 words_Transformers for image recognition at scale-ICLR 2021
2.CSWin Transformer_ A General Vision Transformer Backbone with Cross-Shaped Windows - 2107.00652
3.Aggregating Nested Transformers-2105.12723
4.(DPT)Deformable Patch-based Transformer for Visual Recognition-2107.14467
5.(Conformer)Local Features Coupling Global Representations for Visual Recognition-2105.03889
6.(PVT)Pyramid Vision Transformer: A Versatile Backbone for Dense Prediction without Convolutions
7.(Mobile-Former)Bridging MobileNet and Transformer-2108.05895
8.(CoTNet)Contextual Transformer Networks for Visual Recognition-2107.12292
9.(CrossFormer)A Versatile Vision Transformer Based on Cross-scale Attention-2108.00154
10.(CrossViT)Cross-Attention Multi-Scale Vision Transformer for Image Classification-2103.14899
11.(convmixer)Patches Are All You Need
12.Face Transformer for Recognition
13.(MAE)Masked Autoencoders Are Scalable Vision Learners-2111.06377
14.(PyramidTNT)Improved Transformer-in-Transformer Baselines with Pyramid Architecture-2201.00978
15.(ConvNeXt)A ConvNet for the 2020s-2201.03545
16.Scaling Vision with Sparse Mixture of Experts  # https://arxiv.org/pdf/2106.05974.pdf
17.UniFormer: Unifying Convolution and Self-attention for Visual Recognition   # https://arxiv.org/abs/2201.09450
18.Omnivore: A Single Model for Many Visual Modalities  # https://arxiv.org/abs/2201.08377
19.Training Vision Transformers with Only 2040 Images   # https://arxiv.org/abs/2201.10728




