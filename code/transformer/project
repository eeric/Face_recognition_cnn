1.https://github.com/lucidrains/vit-pytorch                           # several cv transformers
2.https://github.com/asyml/vision-transformer-pytorch                 # only one vit
3.https://github.com/jadore801120/attention-is-all-you-need-pytorch   # attention is all you need
4.https://github.com/JDAI-CV/CoTNet                                   # CoTNet:Contextual Transformer Networks for Visual Recognition
5.https://github.com/pengzhiliang/Conformer                           # Conformer:Local Features Coupling Global Representations for Visual Recognition
6.https://github.com/CASIA-IVA-Lab/DPT                                # DPT: Deformable Patch-based Transformer for Visual Recognition
7.https://github.com/cheerss/CrossFormer                              # CrossFormer: A Versatile Vision Transformer Based on Cross-scale Attention
8.https://github.com/IBM/CrossViT                                     # CrossViTï¼šCross-Attention Multi-Scale Vision Transformer for Image Classification-2103.14899
9.https://github.com/tmp-iclr/convmixer                               # Patches Are All You Need?
10.https://github.com/svip-lab/AS-MLP                                 # AS-MLP: An Axial Shifted MLP Architecture for Vision-arXiv:2107.08391
11.https://github.com/zhongyy/Face-Transformer                        # Face Transformer for Recognition
12.https://github.com/pengzhiliang/MAE-pytorch                        # Masked Autoencoders Are Scalable Vision Learners-2111.06377
13.https://github.com/huawei-noah/CV-Backbones/                       # Transformer in Transformer (TNT) and PyramidTNT
tree/master/tnt_pytorch
14.https://github.com/facebookresearch/ConvNeXt                       # A ConvNet for the 2020s-2201.03545
15.https://github.com/google-research/vmoe                            # Scaling Vision with Sparse Mixture of Experts
16.https://github.com/Sense-X/UniFormer                               # UniFormer: Unifying Convolution and Self-attention for Visual Recognition
17.https://github.com/facebookresearch/omnivore                       # Omnivore: A Single Model for Many Visual Modalities
18.https://github.com/xmu-xiaoma666/External-Attention-pytorch#5-CondConv-Usage   # (CondConv)Conditionally Parameterized Convolutions for Efficient Inference-1904.04971
19.https://github.com/krushi1992/MOA-transformer   # (MoA-Transformer)Aggregating Global Features into Local Vision Transformer-2201.12903
20.https://github.com/ShoufaChen/CycleMLP          # (CycleMLP)A MLP-like Architecture for Dense Prediction-2107.10224
21.https://github.com/NVlabs/FAN                   # Understanding The Robustness in Vision Transformers
22.https://github.com/sail-sg/iFormer              # 





